{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Hackathon - AI for Retail Operations\n",
    "\n",
    "## Challenge Overview\n",
    "- **Data**: 2+ years of pharmacy data (20,000+ products, 10+ locations)\n",
    "- **Problem**: Messy operational data, manual Excel workflows, LLM hallucination risks\n",
    "- **Goal**: Build AI agents that automate retail operations with proper guardrails\n",
    "\n",
    "## Dataset Stats\n",
    "- **Retail Sales**: 1.3M+ transaction lines\n",
    "- **Online Orders**: 1.1M+ order lines\n",
    "- **Locations**: 10+ physical stores + Shopify online\n",
    "- **Time Range**: Sept 2023 - Oct 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Retail Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading retail sales data...\n",
      "Total rows: 1,324,051\n",
      "Columns: 22\n",
      "\n",
      "Column names:\n",
      "['Product', 'Packsize', 'Headoffice ID', 'Barcode', 'OrderList', 'Branch Name', 'Dept Fullname', 'Group Fullname', 'Trade Price', 'RRP', 'Sale Date', 'Sale ID', 'Qty Sold', 'Turnover', 'Vat Amount', 'Sale VAT Rate', 'Turnover ex VAT', 'Disc Amount', 'Discount Band', 'Profit', 'Refund Qty', 'Refund Value']\n"
     ]
    }
   ],
   "source": [
    "# Load retail sales - sample first to avoid memory issues\n",
    "print(\"Loading retail sales data...\")\n",
    "retail_sales = pd.read_csv('data/input/Retail/retail_sales_data_01_09_2023_to_31_10_2025.csv', \n",
    "                           encoding='utf-8-sig',\n",
    "                           low_memory=False)\n",
    "\n",
    "print(f\"Total rows: {len(retail_sales):,}\")\n",
    "print(f\"Columns: {retail_sales.shape[1]}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(retail_sales.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324051 entries, 0 to 1324050\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   Product          1324051 non-null  object \n",
      " 1   Packsize         1312985 non-null  object \n",
      " 2   Headoffice ID    1324051 non-null  int64  \n",
      " 3   Barcode          1316795 non-null  float64\n",
      " 4   OrderList        1323821 non-null  object \n",
      " 5   Branch Name      1324051 non-null  object \n",
      " 6   Dept Fullname    1323978 non-null  object \n",
      " 7   Group Fullname   1323638 non-null  object \n",
      " 8   Trade Price      1324051 non-null  float64\n",
      " 9   RRP              1324051 non-null  float64\n",
      " 10  Sale Date        1324051 non-null  object \n",
      " 11  Sale ID          1324051 non-null  int64  \n",
      " 12  Qty Sold         1324051 non-null  int64  \n",
      " 13  Turnover         1324051 non-null  float64\n",
      " 14  Vat Amount       1324051 non-null  float64\n",
      " 15  Sale VAT Rate    1324051 non-null  float64\n",
      " 16  Turnover ex VAT  1324051 non-null  float64\n",
      " 17  Disc Amount      1324051 non-null  float64\n",
      " 18  Discount Band    211668 non-null   object \n",
      " 19  Profit           1324051 non-null  float64\n",
      " 20  Refund Qty       1324051 non-null  int64  \n",
      " 21  Refund Value     1324051 non-null  float64\n",
      "dtypes: float64(10), int64(4), object(8)\n",
      "memory usage: 222.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "retail_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Packsize</th>\n",
       "      <th>Headoffice ID</th>\n",
       "      <th>Barcode</th>\n",
       "      <th>OrderList</th>\n",
       "      <th>Branch Name</th>\n",
       "      <th>Dept Fullname</th>\n",
       "      <th>Group Fullname</th>\n",
       "      <th>Trade Price</th>\n",
       "      <th>RRP</th>\n",
       "      <th>Sale Date</th>\n",
       "      <th>Sale ID</th>\n",
       "      <th>Qty Sold</th>\n",
       "      <th>Turnover</th>\n",
       "      <th>Vat Amount</th>\n",
       "      <th>Sale VAT Rate</th>\n",
       "      <th>Turnover ex VAT</th>\n",
       "      <th>Disc Amount</th>\n",
       "      <th>Discount Band</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Refund Qty</th>\n",
       "      <th>Refund Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Revive Active Tropical Health Food Supplement ...</td>\n",
       "      <td>30</td>\n",
       "      <td>93754</td>\n",
       "      <td>7.947128e+11</td>\n",
       "      <td>Galway Natural Health Company</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>Vitamins</td>\n",
       "      <td>Revive Active</td>\n",
       "      <td>26.59</td>\n",
       "      <td>59.95</td>\n",
       "      <td>2023-09-01 08:05:00</td>\n",
       "      <td>6219657</td>\n",
       "      <td>1</td>\n",
       "      <td>44.96</td>\n",
       "      <td>5.35</td>\n",
       "      <td>13.5</td>\n",
       "      <td>39.61</td>\n",
       "      <td>14.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catrice True Skin High Cover Concealer 010</td>\n",
       "      <td>0</td>\n",
       "      <td>90866</td>\n",
       "      <td>4.059729e+12</td>\n",
       "      <td>SCL Catrice Make Up</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>Self Selection Stands</td>\n",
       "      <td>Catrice Make Up</td>\n",
       "      <td>2.53</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2023-09-01 08:13:00</td>\n",
       "      <td>6219658</td>\n",
       "      <td>1</td>\n",
       "      <td>4.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Durex Thin Feel 6s</td>\n",
       "      <td>6's</td>\n",
       "      <td>47131</td>\n",
       "      <td>5.052197e+12</td>\n",
       "      <td>Reckitt Benckiser Group</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>OTC : Family Planning</td>\n",
       "      <td>Family Planning</td>\n",
       "      <td>4.20</td>\n",
       "      <td>8.50</td>\n",
       "      <td>2023-09-01 08:25:00</td>\n",
       "      <td>6219659</td>\n",
       "      <td>1</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Riley Applicator Tampons Regular 12 Pack</td>\n",
       "      <td>12</td>\n",
       "      <td>95403</td>\n",
       "      <td>6.309410e+11</td>\n",
       "      <td>We Are Riley</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>Female Toiletries : Hygiene</td>\n",
       "      <td>Female Hygiene</td>\n",
       "      <td>3.70</td>\n",
       "      <td>5.29</td>\n",
       "      <td>2023-09-01 08:27:00</td>\n",
       "      <td>6219660</td>\n",
       "      <td>1</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elave Daily Skin Defence SPF45 50ml</td>\n",
       "      <td>50ml</td>\n",
       "      <td>17710</td>\n",
       "      <td>5.098928e+12</td>\n",
       "      <td>Gardiner Apothecary</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>Skincare</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>10.89</td>\n",
       "      <td>22.95</td>\n",
       "      <td>2023-09-01 08:28:00</td>\n",
       "      <td>6219661</td>\n",
       "      <td>1</td>\n",
       "      <td>22.95</td>\n",
       "      <td>4.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linwoods Flax Seed 425G</td>\n",
       "      <td>425g</td>\n",
       "      <td>14284</td>\n",
       "      <td>5.016887e+12</td>\n",
       "      <td>Wholefoods Wholesale</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>Nutritional Supplements : Diet</td>\n",
       "      <td>Nutritional Supplements</td>\n",
       "      <td>5.30</td>\n",
       "      <td>7.99</td>\n",
       "      <td>2023-09-01 08:29:00</td>\n",
       "      <td>6219662</td>\n",
       "      <td>1</td>\n",
       "      <td>7.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Solpadeine Soluble 24s</td>\n",
       "      <td>24s</td>\n",
       "      <td>2371</td>\n",
       "      <td>5.010215e+12</td>\n",
       "      <td>Pharmax</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>OTC : Analgesics</td>\n",
       "      <td>Analgesics</td>\n",
       "      <td>8.36</td>\n",
       "      <td>14.75</td>\n",
       "      <td>2023-09-01 08:29:00</td>\n",
       "      <td>6219662</td>\n",
       "      <td>1</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MacuSave Eye Food Supplement 30s</td>\n",
       "      <td>30</td>\n",
       "      <td>76204</td>\n",
       "      <td>5.060135e+12</td>\n",
       "      <td>Wholefoods Wholesale</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>Vitamins</td>\n",
       "      <td>Other Vitamins</td>\n",
       "      <td>10.60</td>\n",
       "      <td>20.05</td>\n",
       "      <td>2023-09-01 08:32:00</td>\n",
       "      <td>6219663</td>\n",
       "      <td>1</td>\n",
       "      <td>19.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Actifed Tabs 12s</td>\n",
       "      <td>12s</td>\n",
       "      <td>2271</td>\n",
       "      <td>5.010124e+12</td>\n",
       "      <td>Kenvue (McNeil Healthcare)</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>OTC : Cold &amp; Flu</td>\n",
       "      <td>Cough/Cold/Flu</td>\n",
       "      <td>4.25</td>\n",
       "      <td>8.95</td>\n",
       "      <td>2023-09-01 08:33:00</td>\n",
       "      <td>6219664</td>\n",
       "      <td>1</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Medicare Alcohol Free Cleansing Wipes 10</td>\n",
       "      <td>10</td>\n",
       "      <td>89689</td>\n",
       "      <td>5.099390e+12</td>\n",
       "      <td>Fleming Medical</td>\n",
       "      <td>Baggot St</td>\n",
       "      <td>OTC : First Aid</td>\n",
       "      <td>First aid</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2023-09-01 08:33:00</td>\n",
       "      <td>6219665</td>\n",
       "      <td>1</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.65</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product Packsize  Headoffice ID  \\\n",
       "0  Revive Active Tropical Health Food Supplement ...       30          93754   \n",
       "1         Catrice True Skin High Cover Concealer 010        0          90866   \n",
       "2                                 Durex Thin Feel 6s      6's          47131   \n",
       "3           Riley Applicator Tampons Regular 12 Pack       12          95403   \n",
       "4                Elave Daily Skin Defence SPF45 50ml     50ml          17710   \n",
       "5                            Linwoods Flax Seed 425G     425g          14284   \n",
       "6                             Solpadeine Soluble 24s      24s           2371   \n",
       "7                   MacuSave Eye Food Supplement 30s       30          76204   \n",
       "8                                   Actifed Tabs 12s      12s           2271   \n",
       "9           Medicare Alcohol Free Cleansing Wipes 10       10          89689   \n",
       "\n",
       "        Barcode                      OrderList Branch Name  \\\n",
       "0  7.947128e+11  Galway Natural Health Company   Baggot St   \n",
       "1  4.059729e+12            SCL Catrice Make Up   Baggot St   \n",
       "2  5.052197e+12        Reckitt Benckiser Group   Baggot St   \n",
       "3  6.309410e+11                   We Are Riley   Baggot St   \n",
       "4  5.098928e+12            Gardiner Apothecary   Baggot St   \n",
       "5  5.016887e+12           Wholefoods Wholesale   Baggot St   \n",
       "6  5.010215e+12                        Pharmax   Baggot St   \n",
       "7  5.060135e+12           Wholefoods Wholesale   Baggot St   \n",
       "8  5.010124e+12     Kenvue (McNeil Healthcare)   Baggot St   \n",
       "9  5.099390e+12                Fleming Medical   Baggot St   \n",
       "\n",
       "                    Dept Fullname           Group Fullname  Trade Price  \\\n",
       "0                        Vitamins            Revive Active        26.59   \n",
       "1           Self Selection Stands          Catrice Make Up         2.53   \n",
       "2           OTC : Family Planning          Family Planning         4.20   \n",
       "3     Female Toiletries : Hygiene           Female Hygiene         3.70   \n",
       "4                        Skincare                Skin Care        10.89   \n",
       "5  Nutritional Supplements : Diet  Nutritional Supplements         5.30   \n",
       "6                OTC : Analgesics               Analgesics         8.36   \n",
       "7                        Vitamins           Other Vitamins        10.60   \n",
       "8                OTC : Cold & Flu           Cough/Cold/Flu         4.25   \n",
       "9                 OTC : First Aid                First aid         1.74   \n",
       "\n",
       "     RRP            Sale Date  Sale ID  Qty Sold  Turnover  Vat Amount  \\\n",
       "0  59.95  2023-09-01 08:05:00  6219657         1     44.96        5.35   \n",
       "1   4.65  2023-09-01 08:13:00  6219658         1      4.95        0.93   \n",
       "2   8.50  2023-09-01 08:25:00  6219659         1      6.00        0.71   \n",
       "3   5.29  2023-09-01 08:27:00  6219660         1      5.29        0.00   \n",
       "4  22.95  2023-09-01 08:28:00  6219661         1     22.95        4.29   \n",
       "5   7.99  2023-09-01 08:29:00  6219662         1      7.99        0.00   \n",
       "6  14.75  2023-09-01 08:29:00  6219662         1     13.00        0.00   \n",
       "7  20.05  2023-09-01 08:32:00  6219663         1     19.39        0.00   \n",
       "8   8.95  2023-09-01 08:33:00  6219664         1      7.80        0.00   \n",
       "9   3.80  2023-09-01 08:33:00  6219665         1      3.45        0.65   \n",
       "\n",
       "   Sale VAT Rate  Turnover ex VAT  Disc Amount Discount Band  Profit  \\\n",
       "0           13.5            39.61        14.99           NaN    8.69   \n",
       "1           23.0             4.02         0.00           NaN    1.32   \n",
       "2           13.5             5.29         0.00           NaN    2.33   \n",
       "3            0.0             5.29         0.00           NaN    1.59   \n",
       "4           23.0            18.66         0.00           NaN    7.77   \n",
       "5            0.0             7.99         0.00           NaN    2.69   \n",
       "6            0.0            13.00         0.00           NaN    7.12   \n",
       "7            0.0            19.39         0.00           NaN    7.61   \n",
       "8            0.0             7.80         0.00           NaN    3.24   \n",
       "9           23.0             2.80         0.00           NaN    1.04   \n",
       "\n",
       "   Refund Qty  Refund Value  \n",
       "0           0           0.0  \n",
       "1           0           0.0  \n",
       "2           0           0.0  \n",
       "3           0           0.0  \n",
       "4           0           0.0  \n",
       "5           0           0.0  \n",
       "6           0           0.0  \n",
       "7           0           0.0  \n",
       "8           0           0.0  \n",
       "9           0           0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First few rows\n",
    "retail_sales.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"31/10/2025 19:01\" doesn't match format \"%Y-%m-%d %H:%M:%S\", at position 367137. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert date column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m retail_sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSale Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretail_sales\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSale Date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Basic stats\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate Range:\u001b[39m\u001b[38;5;124m\"\u001b[39m, retail_sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSale Date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m, retail_sales[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSale Date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1108\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1106\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1108\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1110\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:254\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    252\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 254\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    491\u001b[0m     arg,\n\u001b[1;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    509\u001b[0m     arg,\n\u001b[1;32m    510\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[0;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"31/10/2025 19:01\" doesn't match format \"%Y-%m-%d %H:%M:%S\", at position 367137. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Convert date column\n",
    "retail_sales['Sale Date'] = pd.to_datetime(retail_sales['Sale Date'])\n",
    "\n",
    "# Basic stats\n",
    "print(\"Date Range:\", retail_sales['Sale Date'].min(), \"to\", retail_sales['Sale Date'].max())\n",
    "print(f\"\\nUnique Products: {retail_sales['Product'].nunique():,}\")\n",
    "print(f\"Unique Branches: {retail_sales['Branch Name'].nunique()}\")\n",
    "print(f\"Unique Departments: {retail_sales['Dept Fullname'].nunique()}\")\n",
    "print(f\"\\nBranches:\")\n",
    "print(retail_sales['Branch Name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Analysis - Finding the Mess!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data analysis\n",
    "print(\"Missing Data Analysis:\")\n",
    "print(\"=\"*50)\n",
    "missing = retail_sales.isnull().sum()\n",
    "missing_pct = 100 * missing / len(retail_sales)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate product entries with different names\n",
    "print(\"\\nDuplicate Detection - Same Barcode, Different Names:\")\n",
    "print(\"=\"*50)\n",
    "barcode_groups = retail_sales.groupby('Barcode')['Product'].unique()\n",
    "duplicates = barcode_groups[barcode_groups.apply(len) > 1]\n",
    "print(f\"Found {len(duplicates)} barcodes with multiple product names!\")\n",
    "print(\"\\nExamples:\")\n",
    "for barcode, names in list(duplicates.items())[:5]:\n",
    "    print(f\"Barcode {barcode}:\")\n",
    "    for name in names:\n",
    "        print(f\"  - {name}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pricing anomalies - selling below cost\n",
    "print(\"\\nPricing Anomalies - Negative Margins:\")\n",
    "print(\"=\"*50)\n",
    "negative_margin = retail_sales[retail_sales['Profit'] < 0]\n",
    "print(f\"Transactions with negative profit: {len(negative_margin):,} ({100*len(negative_margin)/len(retail_sales):.2f}%)\")\n",
    "print(f\"Total loss from negative margins: €{negative_margin['Profit'].sum():,.2f}\")\n",
    "print(\"\\nTop loss-making products:\")\n",
    "negative_by_product = negative_margin.groupby('Product').agg({\n",
    "    'Profit': 'sum',\n",
    "    'Qty Sold': 'sum',\n",
    "    'Turnover': 'sum'\n",
    "}).sort_values('Profit')\n",
    "print(negative_by_product.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavy discount analysis\n",
    "print(\"\\nHeavy Discounting Analysis:\")\n",
    "print(\"=\"*50)\n",
    "retail_sales['Discount %'] = 100 * retail_sales['Disc Amount'] / (retail_sales['Turnover'] + retail_sales['Disc Amount'])\n",
    "heavy_discount = retail_sales[retail_sales['Discount %'] > 20]\n",
    "print(f\"Transactions with >20% discount: {len(heavy_discount):,} ({100*len(heavy_discount)/len(retail_sales):.2f}%)\")\n",
    "print(f\"Total discount given: €{retail_sales['Disc Amount'].sum():,.2f}\")\n",
    "print(f\"\\nAverage discount rate: {retail_sales['Discount %'].mean():.2f}%\")\n",
    "print(f\"Products with highest average discount:\")\n",
    "discount_by_product = retail_sales.groupby('Product').agg({\n",
    "    'Discount %': 'mean',\n",
    "    'Disc Amount': 'sum',\n",
    "    'Qty Sold': 'sum'\n",
    "}).sort_values('Discount %', ascending=False)\n",
    "print(discount_by_product.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sales Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top performing products\n",
    "print(\"Top 20 Products by Revenue:\")\n",
    "print(\"=\"*50)\n",
    "top_products = retail_sales.groupby('Product').agg({\n",
    "    'Turnover': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Qty Sold': 'sum',\n",
    "    'Trade Price': 'mean',\n",
    "    'RRP': 'mean'\n",
    "}).sort_values('Turnover', ascending=False)\n",
    "\n",
    "top_products['Margin %'] = 100 * top_products['Profit'] / top_products['Turnover']\n",
    "top_products['Avg Selling Price'] = top_products['Turnover'] / top_products['Qty Sold']\n",
    "print(top_products.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by location\n",
    "print(\"\\nSales by Branch:\")\n",
    "print(\"=\"*50)\n",
    "branch_performance = retail_sales.groupby('Branch Name').agg({\n",
    "    'Turnover': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Qty Sold': 'sum',\n",
    "    'Sale ID': 'nunique'\n",
    "}).sort_values('Turnover', ascending=False)\n",
    "branch_performance.columns = ['Revenue €', 'Profit €', 'Units Sold', 'Transactions']\n",
    "branch_performance['Margin %'] = 100 * branch_performance['Profit €'] / branch_performance['Revenue €']\n",
    "branch_performance['Avg Transaction €'] = branch_performance['Revenue €'] / branch_performance['Transactions']\n",
    "print(branch_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales trends over time\n",
    "daily_sales = retail_sales.groupby(retail_sales['Sale Date'].dt.date).agg({\n",
    "    'Turnover': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Sale ID': 'nunique'\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "daily_sales['Turnover'].plot(ax=axes[0], title='Daily Revenue Over Time', color='green', alpha=0.7)\n",
    "axes[0].set_ylabel('Revenue €')\n",
    "axes[0].axhline(daily_sales['Turnover'].mean(), color='red', linestyle='--', alpha=0.5, label='Average')\n",
    "axes[0].legend()\n",
    "\n",
    "daily_sales['Profit'].plot(ax=axes[1], title='Daily Profit Over Time', color='blue', alpha=0.7)\n",
    "axes[1].set_ylabel('Profit €')\n",
    "axes[1].axhline(daily_sales['Profit'].mean(), color='red', linestyle='--', alpha=0.5, label='Average')\n",
    "axes[1].legend()\n",
    "\n",
    "daily_sales['Sale ID'].plot(ax=axes[2], title='Daily Transactions Over Time', color='purple', alpha=0.7)\n",
    "axes[2].set_ylabel('Transactions')\n",
    "axes[2].axhline(daily_sales['Sale ID'].mean(), color='red', linestyle='--', alpha=0.5, label='Average')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average daily revenue: €{daily_sales['Turnover'].mean():,.2f}\")\n",
    "print(f\"Average daily profit: €{daily_sales['Profit'].mean():,.2f}\")\n",
    "print(f\"Average daily transactions: {daily_sales['Sale ID'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Inventory Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inventory snapshot\n",
    "print(\"Loading inventory snapshot...\")\n",
    "inventory = pd.read_csv('data/input/Retail/retail_inventory_snapshot_30_10_25.csv', \n",
    "                        encoding='utf-8-sig',\n",
    "                        low_memory=False)\n",
    "\n",
    "print(f\"Total rows: {len(inventory):,}\")\n",
    "print(f\"Unique products: {inventory['Product'].nunique():,}\")\n",
    "inventory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total inventory value by branch\n",
    "inventory_summary = inventory.groupby('Branch Name').agg({\n",
    "    'Branch Stock Level': 'sum',\n",
    "    'Product': 'count'\n",
    "})\n",
    "inventory_summary.columns = ['Total Units', 'SKU Count']\n",
    "\n",
    "# Calculate value\n",
    "inventory['Stock Value'] = inventory['Branch Stock Level'] * inventory['Trade Price']\n",
    "inventory_value = inventory.groupby('Branch Name')['Stock Value'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Inventory by Branch:\")\n",
    "print(\"=\"*50)\n",
    "inv_df = pd.DataFrame({\n",
    "    'Total Units': inventory_summary['Total Units'],\n",
    "    'SKU Count': inventory_summary['SKU Count'],\n",
    "    'Stock Value €': inventory_value\n",
    "})\n",
    "print(inv_df.sort_values('Stock Value €', ascending=False))\n",
    "print(f\"\\nTotal inventory value: €{inventory['Stock Value'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inventory Optimization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sales velocity for last 30 days\n",
    "recent_sales = retail_sales[retail_sales['Sale Date'] >= retail_sales['Sale Date'].max() - pd.Timedelta(days=30)]\n",
    "\n",
    "# Aggregate by product\n",
    "velocity = recent_sales.groupby('Product').agg({\n",
    "    'Qty Sold': 'sum',\n",
    "    'Turnover': 'sum',\n",
    "    'Profit': 'sum'\n",
    "})\n",
    "\n",
    "velocity.columns = ['Units_30d', 'Revenue_30d', 'Profit_30d']\n",
    "velocity['Daily_Velocity'] = velocity['Units_30d'] / 30\n",
    "\n",
    "# Merge with current stock\n",
    "inventory_agg = inventory.groupby('Product').agg({\n",
    "    'Branch Stock Level': 'sum',\n",
    "    'Trade Price': 'first',\n",
    "    'RRP': 'first'\n",
    "})\n",
    "inventory_agg.columns = ['Current_Stock', 'Cost', 'RRP']\n",
    "\n",
    "# Combine\n",
    "stock_analysis = inventory_agg.join(velocity, how='left').fillna(0)\n",
    "stock_analysis['Days_of_Stock'] = np.where(\n",
    "    stock_analysis['Daily_Velocity'] > 0,\n",
    "    stock_analysis['Current_Stock'] / stock_analysis['Daily_Velocity'],\n",
    "    999\n",
    ")\n",
    "stock_analysis['Stock_Value'] = stock_analysis['Current_Stock'] * stock_analysis['Cost']\n",
    "\n",
    "print(\"Stock Coverage Analysis:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Products with <7 days stock (URGENT): {len(stock_analysis[stock_analysis['Days_of_Stock'] < 7]):,}\")\n",
    "print(f\"Products with 7-21 days stock (OPTIMAL): {len(stock_analysis[(stock_analysis['Days_of_Stock'] >= 7) & (stock_analysis['Days_of_Stock'] <= 21)]):,}\")\n",
    "print(f\"Products with >60 days stock (SLOW MOVERS): {len(stock_analysis[stock_analysis['Days_of_Stock'] > 60]):,}\")\n",
    "print(f\"Products with no sales in last 30 days: {len(stock_analysis[stock_analysis['Units_30d'] == 0]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urgent reorders needed\n",
    "print(\"\\nURGENT REORDERS NEEDED (<7 days stock):\")\n",
    "print(\"=\"*50)\n",
    "urgent = stock_analysis[\n",
    "    (stock_analysis['Days_of_Stock'] < 7) & \n",
    "    (stock_analysis['Daily_Velocity'] > 0)\n",
    "].sort_values('Revenue_30d', ascending=False).head(20)\n",
    "\n",
    "urgent_display = urgent[['Current_Stock', 'Daily_Velocity', 'Days_of_Stock', 'Revenue_30d', 'Profit_30d']]\n",
    "urgent_display.columns = ['Stock', 'Daily Sales', 'Days Left', 'Revenue 30d', 'Profit 30d']\n",
    "print(urgent_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow movers - dead stock\n",
    "print(\"\\nSLOW MOVERS - MARKDOWN CANDIDATES (>60 days stock):\")\n",
    "print(\"=\"*50)\n",
    "slow_movers = stock_analysis[\n",
    "    (stock_analysis['Days_of_Stock'] > 60) & \n",
    "    (stock_analysis['Current_Stock'] > 0)\n",
    "].sort_values('Stock_Value', ascending=False).head(20)\n",
    "\n",
    "slow_display = slow_movers[['Current_Stock', 'Daily_Velocity', 'Days_of_Stock', 'Stock_Value', 'Revenue_30d']]\n",
    "slow_display.columns = ['Stock', 'Daily Sales', 'Days Stock', 'Locked Capital €', 'Revenue 30d']\n",
    "print(slow_display)\n",
    "print(f\"\\nTotal capital locked in slow movers: €{slow_movers['Stock_Value'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Department Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Department analysis\n",
    "dept_performance = retail_sales.groupby('Dept Fullname').agg({\n",
    "    'Turnover': 'sum',\n",
    "    'Profit': 'sum',\n",
    "    'Qty Sold': 'sum',\n",
    "    'Sale ID': 'nunique'\n",
    "}).sort_values('Turnover', ascending=False)\n",
    "\n",
    "dept_performance['Margin %'] = 100 * dept_performance['Profit'] / dept_performance['Turnover']\n",
    "dept_performance.columns = ['Revenue €', 'Profit €', 'Units', 'Transactions', 'Margin %']\n",
    "\n",
    "print(\"Top 20 Departments by Revenue:\")\n",
    "print(\"=\"*50)\n",
    "print(dept_performance.head(20))\n",
    "\n",
    "# Visualize top 10\n",
    "top_10_depts = dept_performance.head(10)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "top_10_depts['Revenue €'].plot(kind='barh', ax=axes[0], color='green')\n",
    "axes[0].set_title('Top 10 Departments by Revenue')\n",
    "axes[0].set_xlabel('Revenue €')\n",
    "\n",
    "top_10_depts['Margin %'].plot(kind='barh', ax=axes[1], color='blue')\n",
    "axes[1].set_title('Top 10 Departments - Margin %')\n",
    "axes[1].set_xlabel('Margin %')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"KEY INSIGHTS & HACKATHON OPPORTUNITIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. DATA QUALITY ISSUES (Perfect for Data-Fix Agent):\")\n",
    "print(f\"   - {len(duplicates)} barcodes have multiple product names\")\n",
    "print(f\"   - {len(negative_margin):,} transactions with negative margins (€{negative_margin['Profit'].sum():,.2f} loss)\")\n",
    "print(f\"   - {len(heavy_discount):,} transactions heavily discounted (>20%)\")\n",
    "print(f\"   - Missing data in multiple columns\")\n",
    "\n",
    "print(\"\\n2. INVENTORY OPTIMIZATION OPPORTUNITIES:\")\n",
    "print(f\"   - {len(stock_analysis[stock_analysis['Days_of_Stock'] < 7]):,} products need URGENT reorder\")\n",
    "print(f\"   - {len(stock_analysis[stock_analysis['Days_of_Stock'] > 60]):,} slow-moving products\")\n",
    "print(f\"   - €{slow_movers['Stock_Value'].sum():,.2f} locked in slow-moving inventory\")\n",
    "print(f\"   - Products with no sales: {len(stock_analysis[stock_analysis['Units_30d'] == 0]):,}\")\n",
    "\n",
    "print(\"\\n3. REVENUE & PROFITABILITY:\")\n",
    "print(f\"   - Total revenue (2 years): €{retail_sales['Turnover'].sum():,.2f}\")\n",
    "print(f\"   - Total profit: €{retail_sales['Profit'].sum():,.2f}\")\n",
    "print(f\"   - Average margin: {100*retail_sales['Profit'].sum()/retail_sales['Turnover'].sum():.2f}%\")\n",
    "print(f\"   - Total discounts given: €{retail_sales['Disc Amount'].sum():,.2f}\")\n",
    "\n",
    "print(\"\\n4. OPERATIONS SCALE:\")\n",
    "print(f\"   - Unique products: {retail_sales['Product'].nunique():,}\")\n",
    "print(f\"   - Total transactions: {retail_sales['Sale ID'].nunique():,}\")\n",
    "print(f\"   - Locations: {retail_sales['Branch Name'].nunique()}\")\n",
    "print(f\"   - Departments: {retail_sales['Dept Fullname'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sample Online Data (Shopify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample online orders (just first 100k rows to avoid memory issues)\n",
    "print(\"Loading online orders sample...\")\n",
    "online_orders = pd.read_csv('data/input/Online/order_line_items.csv', \n",
    "                            encoding='utf-8-sig',\n",
    "                            nrows=100000,\n",
    "                            low_memory=False)\n",
    "\n",
    "print(f\"Sample rows: {len(online_orders):,}\")\n",
    "print(f\"Columns: {online_orders.shape[1]}\")\n",
    "online_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online products\n",
    "print(\"\\nLoading Shopify products...\")\n",
    "online_products = pd.read_csv('data/input/Online/inventory_products.csv', \n",
    "                              encoding='utf-8-sig',\n",
    "                              low_memory=False)\n",
    "\n",
    "print(f\"Online products: {len(online_products):,}\")\n",
    "online_products.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
